{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UQ HW #1\n",
    "Chandler Zachary <br/>\n",
    "MATH 6380 <br/>\n",
    "Due 16 Sep 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.\n",
    "Let $X$ and $Y$ be independent and $\\mathcal{U}[0,1]$. \n",
    "* Analytically determine the *pdf* of $X+Y$, and then compute the mean and variance of $X+Y$.\n",
    "* Use a normalized histogram on [0,2] with 10 bins to approximate the pdf of $X+Y$.  Do this twice with 100 and 1000 samples of $(X,Y)$.  Use the histogram to numerically compute the mean and variance, and compare with the analytical result from the first part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response\n",
    "\n",
    "The pdf $f_Z(z)$ can be derived using the bivariate transformation method. Let $Z = X + Y$ and $W = X$. Then,<br/> \n",
    "\\begin{align*} \n",
    "g_1(x, y) &= z = x + y \\\\ \n",
    "g_2(x, y) &= w = x, \\\\ \n",
    "\\end{align*} \n",
    "\n",
    "and \n",
    "\\begin{align*} \n",
    "g_1^{-1}(w, z) &= y = z - w \\\\ \n",
    "g_2^{-1}(w, z) &= x = w. \\\\ \n",
    "\\end{align*}\n",
    "\n",
    "The joint distribution of $X$ and $Y$ is given by $$f_{X, Y}(x, y) \\overset{ind}{=} f_X(x)f_Y(y) = \\mathcal{I}_{[0, 1]}(x)\\mathcal{I}_{[0, 1]}(y).$$ Thus, the joint distribution $f_{W, Z}$ is given by $$f_{W, Z} = f_{X, Y}(g_1^{-1}(w, z), g_2^{-1}(w, z))|J| = f_X(w)f_Y(z - w)|J|.$$ \n",
    "\n",
    "We compute $|J|$ as: \n",
    "$$|J| = \n",
    "\\begin{Vmatrix} \n",
    "\\frac{\\partial g_1^{-1}}{\\partial w} & \\frac{\\partial g_1^{-1}}{\\partial z} \\\\ \n",
    "\\frac{\\partial g_2^{-1}}{\\partial w} & \\frac{\\partial g_2^{-1}}{\\partial z} \\\\\n",
    "\\end{Vmatrix} = \n",
    "\\begin{Vmatrix} \n",
    "-1 & 1 \\\\ \n",
    "1 & 0 \\\\\n",
    "\\end{Vmatrix} = \\big|-1\\big| = 1$$ \n",
    "\n",
    "Therefore, $$f_Z(z) = \\int\\limits_{-\\infty}^{+\\infty}f_X(w)f_Y(z - w)|J|dw = \\int\\limits_{-\\infty}^{+\\infty}I_{[0, 1]}(w)I_{[0, 1]}(z - w)dw.$$\n",
    "\n",
    "Now, $z = x + y \\Rightarrow 0 \\leq z \\leq 2$, and $w = x \\Rightarrow 0 \\leq w \\leq 1.$ Therefore, $0 \\leq z \\leq 1$ when $w \\leq z$, and $1 < z \\leq 2$ when $z - 1 \\leq w.$ Thus, $$w \\leq z \\Rightarrow \\int\\limits_{0}^{z}(1)(1)dw = w\\big|_0^z = z,$$ and $$z - 1 \\leq w \\Rightarrow \\int\\limits_{z - 1}^{1}(1)(1)dw = w\\big|_{z - 1}^1 = 1 - (z - 1) = 2 - z.$$ Thus, the pdf of $Z$ is: $$f_Z(z) = \n",
    "\\begin{cases} \n",
    "0 & z < 0 \\\\ \n",
    "z & 0 \\leq z \\leq 1 \\\\ \n",
    "2 - z & 1 < z \\leq 2 \\\\ \n",
    "1 & z > 2 \\\\ \n",
    "\\end{cases}$$\n",
    "\n",
    "To find $\\mathbb{E}[Z]$ and $var(Z)$:\n",
    "$$\\begin{align*}\n",
    "\\mathbb{E}[Z] &\\overset{def}{=} \\int\\limits_{-\\infty}^{+\\infty} zf_Z(z)dz \\\\\n",
    "\\\\\n",
    "&= \\int\\limits_{0}^{1} z^2dz + \\int\\limits_{1}^{2} 2z - z^2dz \\\\\n",
    "\\\\\n",
    "&= \\frac{z^3}{3}\\bigg|_0^1 + \\bigg(z^2 - \\frac{z^3}{3}\\bigg)_1^2 = 1 \\\\\n",
    "\\end{align*}$$\n",
    "<br/>\n",
    "$$\\begin{align*}\n",
    "var(Z) &= \\mathbb{E}\\big(Z^2\\big) - \\big(\\mathbb{E}(Z)\\big)^2 \\\\\n",
    "\\\\\n",
    "\\mathbb{E}[Z^2] &= \\int\\limits_{-\\infty}^{+\\infty} z^2f_Z(z)dz \\\\\n",
    "\\\\\n",
    "&= \\int\\limits_{0}^{1} z^3dz + \\int\\limits_{1}^{2} 2z^2 - z^3dz \\\\\n",
    "\\\\\n",
    "&= \\frac{z^4}{4}\\bigg|_0^1 + \\bigg(\\frac{2}{3}z^3 - \\frac{1}{4}z^4\\bigg)_1^2 = \\frac{7}{6} \\\\\n",
    "\\\\\n",
    "\\Rightarrow var(Z) &= \\frac{7}{6} - 1 = \\frac{1}{6} \\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform\n",
    "import random\n",
    "random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = uniform.rvs(0, 1, 100)\n",
    "y1 = uniform.rvs(0, 1, 100)\n",
    "z1 = x1 + y1\n",
    "\n",
    "x2 = uniform.rvs(0, 1, 1000)\n",
    "y2 = uniform.rvs(0, 1, 1000)\n",
    "z2 = x2 + y2\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5), sharex = False, sharey = False)\n",
    "ax1.hist(z1, bins = 10, range = [0, 2], density = True)\n",
    "ax2.hist(z2, bins = 10, range = [0, 2], density = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "\n",
    "1000 bacteria are placed in twenty Petri dishes and allowed to grow(different number of bacteria per dish).  The growth rate $a$ is assumed to be *normally* distributed with unknown mean and variance,  and after 1 day, the following populations are observed:\n",
    "\n",
    "* Analytically determine the pdf of the population at 1 day(if possible) (Hint, read about the **lognormal distribution**)\n",
    "\n",
    "* Given the data, find the maximum likelihood estimate of the mean and variance of $a$.  You may do this numerically or mathematically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response\n",
    "\n",
    "Let the distribution of the population in each dish after time $t$ be a random variable $X_i(t)$, with $i = 1, \\dots, 20$. Then $X_i(t) = 1000e^{a_it}$, where $a_i$ is the growth rate in dish $i$, and $t$ is time in days. Now, $a_i \\sim N(\\mu, \\sigma^2) \\Rightarrow X_i \\sim lognormal(\\mu, \\sigma^2)$, which we will show presently.\n",
    "\n",
    "Observe that at $t = 1$, $X_i(1) = 1000e^{a_i}$, and $a_i = \\text{ln}\\big(\\frac{X_i}{1000}\\big)$. We use this fact, along with the univariate transformation, to derive the pdf for $X_i(t)$. Since $a_i \\sim N(\\mu, \\sigma^2)$, the pdf of $a_i$ is $$f_A(a_i) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\bigg(\\frac{-(a_i - \\mu)^2}{2\\sigma^2}\\bigg).$$\n",
    "\n",
    "Define $a_i = g^{-1}(x_i) = \\text{ln}\\big(\\frac{x_i}{1000}\\big)$, as above, which is a monotone transformation, and observe that $f_A(a_i)$ is continuous for all values of $a_i \\in A$, and <br/> \n",
    "\n",
    "$$\\frac{d}{dx_i}\\text{ln}\\bigg(\\frac{x_i}{1000}\\bigg) = \\frac{1}{1000x_i},$$ which is continuous for $x_i > 0$. Thus, we can write: <br/>\n",
    "\n",
    "$$f_{X}(x_i) = f_A\\big(g^{-1}(x)\\big)\\bigg|\\frac{d}{dx_i}\\big(g^{-1}(x)\\big)\\bigg| = \\frac{1}{1000x_i\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\Bigg[\\frac{-\\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2}{2\\sigma^2}\\Bigg]$$\n",
    "\n",
    "This verifies that the normal growth rate implies lognormal population growth. Since the mean and variance are the same for both distributions, we can derive the maximum likelihood estimates of the mean and variance using the joint pdf of $X_i$.\n",
    "\n",
    "Making use of the likelihood function, the joint pdf of $X_i$ is: <br/>\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\mu, \\sigma^2 | x_1, x_2, \\dots, x_{20}) &= f(x_1, x_2, \\dots, x_{20} | \\mu, \\sigma^2) \\\\\n",
    "\\\\\n",
    "&= \\prod_{i=1}^{20}f_{X}(x_i) \\\\\n",
    "\\\\\n",
    "&= \\prod_{i=1}^{20} \\frac{1}{1000x_i\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\Bigg[\\frac{-\\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2}{2\\sigma^2}\\Bigg] \\\\\n",
    "\\\\\n",
    "\\Rightarrow \\text{ln}\\big(\\mathcal{L}(\\mu, \\sigma^2 | x_1, x_2, \\dots, x_{20})\\big) &= \\text{ln}f(x_1, x_2, \\dots, x_{20} | \\mu, \\sigma^2) \\\\\n",
    "\\\\\n",
    "&= \\text{ln}\\Bigg(\\prod_{i=1}^{20} \\frac{1}{1000x_i\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\Bigg[\\frac{-\\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2}{2\\sigma^2}\\Bigg]\\Bigg) \\\\\n",
    "\\\\\n",
    "&\\overset{ind}{=} \\sum\\limits_{i=1}^{20}\\text{ln}\\Bigg(\\frac{1}{1000x_i\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\Bigg[\\frac{-\\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2}{2\\sigma^2}\\Bigg]\\Bigg) \\\\\n",
    "\\\\\n",
    "&= \\sum\\limits_{i=1}^{20} \\Bigg[\\text{ln}(1) - \\text{ln}(1000) - \\text{ln}(x_i) - \\text{ln}\\sqrt{2\\pi} - \\text{ln}\\sqrt{\\sigma^2} - \\bigg(\\frac{\\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2}{2\\sigma^2}\\bigg)\\Bigg] \\\\\n",
    "\\\\\n",
    "&= \\sum\\limits_{i=1}^{20} \\Bigg[\\text{ln}(1) - \\text{ln}(1000) - \\text{ln}(x_i) - \\frac{1}{2}\\text{ln}(2\\pi) - \\frac{1}{2}\\text{ln}\\sigma^2 - \\bigg(\\frac{\\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2}{2\\sigma^2}\\bigg)\\Bigg] \\\\\n",
    "\\\\\n",
    "&= 0 - 20\\text{ln}(1000) - 10\\text{ln}(2\\pi) - 10\\text{ln}\\sigma^2 - \\sum\\limits_{i=1}^{20}\\text{ln}(x_i) - \\sum\\limits_{i=1}^{20}\\frac{\\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2}{2\\sigma^2} \\\\\n",
    "\\\\\n",
    "&= - 20\\text{ln}(1000) - 10\\text{ln}(2\\pi) - 10\\text{ln}\\sigma^2 - \\sum\\limits_{i=1}^{20}\\text{ln}(x_i) - \\sum\\limits_{i=1}^{20}\\frac{\\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2}{2\\sigma^2} \\\\\n",
    "\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Next, we take the first partial derviatives of this log-likelihood function with respect to $\\mu$ and $\\sigma^2$, then set them equal to zero to arrive at the first order conditions:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial\\text{ln}\\mathcal{L}}{\\partial \\mu} &= \\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^{20} -2\\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big) \\\\\n",
    "\\\\\n",
    "&= \\frac{-1}{\\sigma^2}\\sum\\limits_{i=1}^{20} \\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big) \\\\\n",
    "\\\\\n",
    "&= \\frac{-1}{\\sigma^2}\\Bigg(\\sum\\limits_{i=1}^{20} \\text{ln}\\big(\\frac{x_i}{1000}\\big) - 20\\mu\\Bigg) \\\\\n",
    "\\\\\n",
    "&= \\frac{1}{\\sigma^2}\\Bigg(20\\mu - \\sum\\limits_{i=1}^{20} \\text{ln}\\big(\\frac{x_i}{1000}\\big)\\Bigg) \\\\\n",
    "\\\\\n",
    "\\overset{FOC}{\\Rightarrow} \\frac{\\partial\\text{ln}\\mathcal{L}}{\\partial \\mu} \\overset{set}{=} 0 &\\Rightarrow \\frac{1}{\\sigma^2}\\Bigg(20\\mu - \\sum\\limits_{i=1}^{20} \\text{ln}\\big(\\frac{x_i}{1000}\\big)\\Bigg) = 0 \\\\\n",
    "\\\\\n",
    "&\\Leftrightarrow 20\\mu - \\sum\\limits_{i=1}^{20} \\text{ln}\\big(\\frac{x_i}{1000}\\big) = 0 \\\\\n",
    "\\\\\n",
    "&\\Leftrightarrow 20\\mu = \\sum\\limits_{i=1}^{20} \\text{ln}\\big(\\frac{x_i}{1000}\\big) \\\\\n",
    "\\\\\n",
    "&\\Leftrightarrow \\hat{\\mu}_{MLE} = \\frac{1}{20} \\sum\\limits_{i=1}^{20} \\text{ln}\\big(\\frac{x_i}{1000}\\big) \\\\\n",
    "\\\\\n",
    "\\frac{\\partial\\text{ln}\\mathcal{L}}{\\partial \\sigma^2} &= \\frac{-10}{\\sigma^2} + \\frac{1}{2\\big(\\sigma^2\\big)^2}\\sum\\limits_{i=1}^{20} \\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2 \\\\\n",
    "\\\\\n",
    "\\overset{FOC}{\\Rightarrow} \\frac{\\partial\\text{ln}\\mathcal{L}}{\\partial \\sigma^2} \\overset{set}{=} 0 &\\Rightarrow \\frac{-10}{\\sigma^2} + \\frac{1}{2\\big(\\sigma^2\\big)^2}\\sum\\limits_{i=1}^{20} \\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2 = 0 \\\\\n",
    "\\\\\n",
    "&\\Leftrightarrow \\frac{-10}{\\sigma^2} = -\\frac{1}{2\\big(\\sigma^2\\big)^2}\\sum\\limits_{i=1}^{20} \\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2 \\\\\n",
    "\\\\\n",
    "&\\Leftrightarrow 20 = \\frac{1}{\\big(\\sigma^2\\big)}\\sum\\limits_{i=1}^{20} \\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\mu\\big)^2 \\\\\n",
    "&\\Leftrightarrow \\hat{\\sigma}^2_{MLE} = \\frac{1}{20}\\sum\\limits_{i=1}^{20} \\big(\\text{ln}\\big(\\frac{x_i}{1000}\\big) - \\hat{\\mu}\\big)^2 \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2136. 2143. 1969. 1928. 2020. 2033. 2007. 1895. 2047. 2108. 1957. 2077.\n",
      " 2142. 1837. 2048. 1871. 1973. 1978. 1982. 2017.]\n",
      "Mean estimate: 0.6964321223178728 , Variance estimate: 0.0018181330512784606\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pop1day=np.array([2136., 2143., 1969., 1928., 2020., 2033. ,2007., 1895., 2047. ,2108., 1957. ,2077.,\n",
    " 2142. ,1837., 2048., 1871., 1973., 1978., 1982., 2017.])\n",
    "print(pop1day)\n",
    "\n",
    "mu_hat = (1/20)*np.sum(np.log(pop1day/1000))\n",
    "sigma_sqd_hat = (1/20)*np.sum((np.log(pop1day/1000) - mu_hat)**2)\n",
    "\n",
    "print('Mean estimate:', mu_hat, ',', 'Variance estimate:', sigma_sqd_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. \n",
    "Given the same data as in Problem  #2, but the initial population in each petri dish is approximate (i.e. treat as $\\mathcal{U}[900,1100]$).\n",
    "\n",
    "* Find the joint pdf of the population at 1 day (in terms of the unknown parameters in $a$)\n",
    "* Set up, but do not solve, the estimate for the mean and variance of $a$. \n",
    "* Set up, but do not solve, the probability of the population being greater than 4000 after 2 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Response\n",
    "\n",
    "Let $X_i(0)$ be uniform[900, 1100] random variables, where $X_i(0) = x_i(0)$ is the initial population of bacteria in dish $i$, for $i = 1, \\dots, 20$. Proceeding as in (2), $X_i(t) = X_i(0)e^{a_it}, \\; t > 0,$ is the population at time $t$ in each dish, and $a_i = \\frac{1}{t}\\text{ln}\\big(\\frac{X_i(t)}{X_i(0)}\\big)$. In this form, $X_i(t)$ is now a composed function of two random variables: $X_i(0), \\; a_i$. Therefore, we must derive the joint pdf of $X_i(t)$ using the bivariate transformation method.\n",
    "\n",
    "Let $$\n",
    "\\begin{align*}\n",
    "g_1(x_i(0), a_i) &= x_i(t) = x_i(0)e^{a_it} \\\\\n",
    "g_2(x_i(0), a_i) &= w = x_i(0),\n",
    "\\end{align*}\n",
    "$$ then $$\n",
    "\\begin{align*}\n",
    "g^{-1}_1(w, x_i(t)) &= a_i = \\frac{1}{t}\\text{ln}\\big(\\frac{x_i(t)}{w}\\big) \\\\\n",
    "g^{-1}_2(w, x_i(t)) &= x_i(0) = w\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The joint distribution of $X(0)$ and $A$ is given by: $$f_{X(0), A}(x_i(0), a_i) = \\bigg(\\frac{1}{200}\\mathcal{I}_{[900, 1100]}\\big(x_i(0)\\big)\\bigg)\\bigg(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\bigg[\\frac{-(a_i - \\mu)^2}{2\\sigma^2}\\bigg]\\bigg),$$ \n",
    "<br/>\n",
    "where we make the assumption that the initial population and the growth rate are independent, and the joint distribution \n",
    "<br/>\n",
    "$f_{W, Z}$ is given by $$f_{W, X(t)} = f_{X(0), A}(g_1^{-1}(w, x_i(t)), g_2^{-1}(w, x_i(t)))|J| = f_{X(0)}(w)f_A\\bigg(\\frac{1}{t}\\text{ln}\\big(\\frac{x_i(t)}{w}\\big)\\bigg)|J|.$$\n",
    "\n",
    "We compute $|J|$ as: \n",
    "$$|J| = \n",
    "\\begin{Vmatrix} \n",
    "\\frac{\\partial g_1^{-1}}{\\partial w} & \\frac{\\partial g_1^{-1}}{\\partial x_i(t)} \\\\ \n",
    "\\frac{\\partial g_2^{-1}}{\\partial w} & \\frac{\\partial g_2^{-1}}{\\partial x_i(t)} \\\\\n",
    "\\end{Vmatrix} = \n",
    "\\begin{Vmatrix} \n",
    "\\frac{-1}{w} & \\frac{1}{x_i(t)t} \\\\ \n",
    "1 & 0 \\\\\n",
    "\\end{Vmatrix} = \\bigg|\\frac{1}{x_i(t)t}\\bigg| = \\frac{1}{x_i(t)t}$$\n",
    "\n",
    "Therefore, the joint pdf is \n",
    "$$\n",
    "\\begin{align*}\n",
    "f_{X(0)}(w)f_A\\bigg(\\frac{1}{t}\\text{ln}\\big(\\frac{x_i(t)}{w}\\big)\\bigg)|J| &= \\frac{1}{200\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\bigg[\\frac{-\\big(\\frac{1}{t}\\text{ln}\\big(\\frac{x_i(t)}{x_i(0)}\\big) - \\mu\\big)^2}{2\\sigma^2}\\bigg]\\frac{1}{x_i(t)t} \\\\\n",
    "\\\\\n",
    "&= \\frac{1}{200x_i(t)t\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\bigg[\\frac{-\\big(\\frac{1}{t}\\text{ln}\\big(\\frac{x_i(t)}{x_i(0)}\\big) - \\mu\\big)^2}{2\\sigma^2}\\bigg] \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "When $t = 1$, this is $$\\frac{1}{200x_i(1)\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\bigg[\\frac{-\\big(\\text{ln}\\big(\\frac{x_i(1)}{x_i(0)}\\big) - \\mu\\big)^2}{2\\sigma^2}\\bigg]$$\n",
    "<br/>\n",
    "\n",
    "To arrive at estimates of the mean and variance, set up the likelihood equation:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f_{X(t)}(x_i(t)) &= \\int_{900}^{1100}f_{X(t), X(0)}(x_i(t), x_i(0)) dx_i(0) \\\\\n",
    "\\\\\n",
    "&= \\int_{900}^{1100}\\frac{1}{200x_i(t)t\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\bigg[\\frac{-\\big(\\frac{1}{t}\\text{ln}\\big(\\frac{x_i(t)}{x_i(0)}\\big) - \\mu\\big)^2}{2\\sigma^2}\\bigg] dx_i(0) \\\\\n",
    "\\\\\n",
    "\\Rightarrow \\mathcal{L}(\\mu, \\sigma^2 | x_1, x_2, \\dots, x_{20}) &= \\prod_{i=1}^{20}\\int_{900}^{1100}\\frac{1}{200x_i(t)t\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\bigg[\\frac{-\\big(\\frac{1}{t}\\text{ln}\\big(\\frac{x_i(t)}{x_i(0)}\\big) - \\mu\\big)^2}{2\\sigma^2}\\bigg] dx_i(0)\n",
    "\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "and the first order conditions can be solved to determine $(\\hat{\\mu}, \\hat{\\sigma}^2)$:\n",
    "<br/>\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial\\mu} = 0, \\quad \\frac{\\partial\\mathcal{L}}{\\partial\\sigma^2} = 0$$\n",
    "<br/>\n",
    "\n",
    "The probability of the population being greater than 4000 after 2 days is given by:\n",
    "\n",
    "$$\\mathbb{P}(X_i(2) > 4000) = \\int\\limits_{4000}^{\\infty}\\int\\limits_{900}^{1100}\\frac{1}{400x_i(2)\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\bigg[\\frac{-\\big(\\frac{1}{2}\\text{ln}\\big(\\frac{x_i(2)}{x_i(0)}\\big) - \\mu\\big)^2}{2\\sigma^2}\\bigg]dx_i(0)dx_i(t)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
